This is an experiment of making a Morphic-inspired direct manipulation GUI framework in Erlang.  The rendering is done via the Ex11 work, which was originally done by Joe Armstrong.  Subsequently @skvamme on github modified it to compile on his platforms and that is what this one is right now based on.  The graphical model of X11 is mostly outdated so we just use it as a virtual framebuffer and will implement most of stuff by ourselves.

-----------------

So, the idea here is to implement a direct manipulation based graphical framework on top of a very strict separation among processes.  By modelling a graphical object (a morph) be a process in Erlang, we can be honest about no-sharing.

A problem is that Erlang is still on the "message sending" paradigm; by default only one object can receive a message. When an event, or a change on an object needs to be felt by other objects around it, we'd need an additional mechanism.

Also, in the current implementation of a 2.5 dimension scene graph, there is a need to find who the recipient should be for a particular user event (say, a click needs to go to the front most morph at the spot.)  What is a good idiom to do this?

- We would have a "view" of the scene, kept at the morphic framework and the event routing happens based on the view.  (The objects may subsequently changed off from the view.)

- We painstakingly move in the lock-step manner to figure out the position of each morph, etc. via rpc.

- Or, just declare that 2.5D illustion is not the right abstraction and come up with something else.
